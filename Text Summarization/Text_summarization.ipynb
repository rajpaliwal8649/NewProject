{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DEll\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DEll\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DEll\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTER THE BLOG TEXT:  During the last year, we have been piloting the Unspoken Smiles after-school program with a small group of students at Ember Charter Schools in Brooklyn and have seen dramatic improvements with all of our students showing an increase in their brushing routines at home and a decrease of plaques and tooth decay.    While we have seen measurable success, with school closures due to COVIT-19, the lives and routines of 1.1 million NYC children, have no doubt prompt broader upheaval in a moment of profound anxiety for New Yorkers.    That's why we launched the Unspoken Smiles Virtual classroom, a new program that connects career role models over video chat to local primary schools throughout the five boroughs on topics related to oral health and well-being. \n"
     ]
    }
   ],
   "source": [
    "blog_text = input(\"ENTER THE BLOG TEXT: \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' During the last year, we have been piloting the Unspoken Smiles after-school program with a small group of students at Ember Charter Schools in Brooklyn and have seen dramatic improvements with all of our students showing an increase in their brushing routines at home and a decrease of plaques and tooth decay.', 'While we have seen measurable success, with school closures due to COVIT-19, the lives and routines of 1.1 million NYC children, have no doubt prompt broader upheaval in a moment of profound anxiety for New Yorkers.', \"That's why we launched the Unspoken Smiles Virtual classroom, a new program that connects career role models over video chat to local primary schools throughout the five boroughs on topics related to oral health and well-being.\"]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "sentence_list=nltk.sent_tokenize(blog_text)\n",
    "print(sentence_list)\n",
    "print(len(sentence_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating copy of sentence tokenizing list\n",
    "change_sentence_list = sentence_list.copy()\n",
    "\n",
    "\n",
    "# removing all punctuations\n",
    "for i in range(0,len(change_sentence_list)):\n",
    "    change_sentence_list[i] = re.sub(r'[^\\w\\s]','',change_sentence_list[i])\n",
    "    \n",
    "\n",
    "# stopwords list and lemmatizer\n",
    "stopwords_list=stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "#splitting sentences into words and storing them in place of sentences as list of words\n",
    "for i in range(0,len(change_sentence_list)):\n",
    "    change_sentence_list[i] = change_sentence_list[i].split()\n",
    "\n",
    "# a list to store unique important words\n",
    "unique_words=[]\n",
    "\n",
    "# lemmitizing , stemming and removing stopwords and digits from words lists\n",
    "for i in range(0,len(change_sentence_list)):\n",
    "    b=[]\n",
    "    for j in range(0,len(change_sentence_list[i])):\n",
    "        change_sentence_list[i][j]=change_sentence_list[i][j].lower()\n",
    "        \n",
    "        change_sentence_list[i][j]=lemmatizer.lemmatize(change_sentence_list[i][j]) \n",
    "        \n",
    "        if change_sentence_list[i][j] not in stopwords_list and change_sentence_list[i][j].isnumeric()!=True:\n",
    "            b.append(change_sentence_list[i][j])\n",
    "            unique_words.append(change_sentence_list[i][j])\n",
    "    \n",
    "    change_sentence_list[i]=b        \n",
    "\n",
    "\n",
    "#removing the words that are repeated by converting list to set   \n",
    "unique_words = list(set(unique_words))\n",
    "unique_words.sort()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>afterschool</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anxiety</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>borough</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>broader</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brooklyn</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>virtual</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wellbeing</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yorkers</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  1  2\n",
       "afterschool  1  0  0\n",
       "anxiety      0  1  0\n",
       "borough      0  0  1\n",
       "broader      0  1  0\n",
       "brooklyn     1  0  0\n",
       "...         .. .. ..\n",
       "video        0  0  1\n",
       "virtual      0  0  1\n",
       "wellbeing    0  0  1\n",
       "year         1  0  0\n",
       "yorkers      0  1  0\n",
       "\n",
       "[64 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BAG OF WORDS\n",
    "bag_of_words={}\n",
    "for j in range(0,len(change_sentence_list)):\n",
    "    b=[]\n",
    "    for i in unique_words:\n",
    "        if i in change_sentence_list[j]:\n",
    "            b.append(change_sentence_list[j].count(i))\n",
    "        else:\n",
    "            b.append(0)\n",
    "    bag_of_words[j] = b\n",
    "    \n",
    "bow_df=pd.DataFrame(bag_of_words,index=unique_words)\n",
    "bow_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>afterschool</th>\n",
       "      <td>2.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anxiety</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.098612</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>borough</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>broader</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.098612</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brooklyn</th>\n",
       "      <td>2.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>virtual</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wellbeing</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>2.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yorkers</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.098612</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0         1         2\n",
       "afterschool  2.098612  0.000000  0.000000\n",
       "anxiety      0.000000  2.098612  0.000000\n",
       "borough      0.000000  0.000000  2.098612\n",
       "broader      0.000000  2.098612  0.000000\n",
       "brooklyn     2.098612  0.000000  0.000000\n",
       "...               ...       ...       ...\n",
       "video        0.000000  0.000000  2.098612\n",
       "virtual      0.000000  0.000000  2.098612\n",
       "wellbeing    0.000000  0.000000  2.098612\n",
       "year         2.098612  0.000000  0.000000\n",
       "yorkers      0.000000  2.098612  0.000000\n",
       "\n",
       "[64 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tf-IDF\n",
    "document_freq=[]\n",
    "for i in range(0,len(unique_words)):\n",
    "    b=0\n",
    "    for j in change_sentence_list:\n",
    "        if unique_words[i] in j:\n",
    "            b=b+1\n",
    "    document_freq.append(math.log(len(change_sentence_list)/b)+1)   \n",
    "\n",
    "tf_idf={}\n",
    "for i in range(0,len(change_sentence_list)):\n",
    "    tf_idf[i] = bow_df[i]*document_freq\n",
    "\n",
    "tfidf_df = pd.DataFrame(tf_idf)\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.051683</td>\n",
       "      <td>0.066403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.051683</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.033405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.066403</td>\n",
       "      <td>0.033405</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2\n",
       "0  1.000000  0.051683  0.066403\n",
       "1  0.051683  1.000000  0.033405\n",
       "2  0.066403  0.033405  1.000000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COSINE SIMILARITY MATRIX\n",
    "\n",
    "sim_matrix={}\n",
    "for i in range(0,len(change_sentence_list)):\n",
    "    b=[]\n",
    "    for j in range(0,len(change_sentence_list)):\n",
    "        a = np.dot(tfidf_df[i],tfidf_df[j])\n",
    "        a = a/(np.linalg.norm(tfidf_df[i])*np.linalg.norm(tfidf_df[j]))\n",
    "        b.append(a)\n",
    "    sim_matrix[i]=b\n",
    "sim_matrix=pd.DataFrame(sim_matrix)\n",
    "sim_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 27, 1: 21, 2: 25}\n"
     ]
    }
   ],
   "source": [
    "# A dictionary which stores the sentence index and the points sentence has by \n",
    "sent_ranks={}\n",
    "for i in range(0,len(change_sentence_list)):\n",
    "    a=0\n",
    "    for j in range(0,len(unique_words)):\n",
    "        a=a+bow_df[i][j]\n",
    "    sent_ranks[i] = a\n",
    "print(sent_ranks)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 27), (2, 25), (1, 21)]\n",
      "Enter the number of sentences you want to see in summary: 1\n",
      "\n",
      "  During the last year, we have been piloting the Unspoken Smiles after-school program with a small group of students at Ember Charter Schools in Brooklyn and have seen dramatic improvements with all of our students showing an increase in their brushing routines at home and a decrease of plaques and tooth decay.\n"
     ]
    }
   ],
   "source": [
    "# Converting the dictionary to list and sorting it by points\n",
    "sent_ranks= sorted(sent_ranks.items(), key=lambda x: x[1],reverse=True)    \n",
    "print(sent_ranks)\n",
    "\n",
    "# Making a list of important sentences and sorting them by the sentence index\n",
    "imp_sent=[]\n",
    "num_sentences = int(input(\"Enter the number of sentences you want to see in summary: \"))\n",
    "if(num_sentences<=len(sentence_list)):\n",
    "    for i in range(0,num_sentences):\n",
    "        imp_sent.append(sent_ranks[i][0])\n",
    "    imp_sent.sort()\n",
    "    for i in range(0,num_sentences):\n",
    "        print(\"\\n\",sentence_list[imp_sent[i]])\n",
    "else:\n",
    "    print(\"Text has less number of sentences than demanded in the summary!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
